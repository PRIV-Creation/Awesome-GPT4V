 <!-- # <p align=center>`awesome gpt4v`</p> -->
[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://GitHub.com/Naereen/StrapDown.js/graphs/commit-activity)
[![PR's Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat)](http://makeapullrequest.com) 

<br />
<p align="center">
  <h1 align="center">Awesome GPT4V</h1>
</p>
<br />

We are focusing on evaluation and analysis of GPT4-V(ision).

**A Comprehensive Evaluation of GPT-4V on Knowledge-Intensive Visual Question Answering.**<br>
*Yunxin Li, Longyue Wang, Baotian Hu, Xinyu Chen, Wanqi Zhong, Chenyang Lyu, Min Zhang.*<br>
arXiv 2023.11. [[PDF](https://arxiv.org/abs/2311.07536)]

**ShareGPT4V: Improving Large Multi-Modal Models with Better Captions.**<br>
*Lin Chen, Jisong Li, Xiaoyi Dong, Pan Zhang, Conghui He, Jiaqi Wang, Feng Zhao, Dahua Lin.*<br>
arXiv 2023.11. [[PDF](http://arxiv.org/abs/2311.12793v1)]

**GPT-4V(ision) for Robotics: Multimodal Task Planning from Human Demonstration.**<br>
*Naoki Wake, Atsushi Kanehira, Kazuhiro Sasabuchi, Jun Takamatsu, Katsushi Ikeuchi.*<br>
arXiv 2023.11. [[PDF](http://arxiv.org/abs/2311.12015v1)]

**To See Is to Believe: Prompting GPT-4V for Better Visual Instruction Tuning.**<br>
*Junke Wang, Lingchen Meng, Zejia Weng, Bo He, Zuxuan Wu, Yu-Gang Jiang.*<br>
arXiv 2023.11. [[PDF](http://arxiv.org/abs/2311.07574v1)]

**GPT-4V in Wonderland: Large Multimodal Models for Zero-Shot Smartphone GUI Navigation.**<br>
*An Yan, Zhengyuan Yang, Wanrong Zhu, Kevin Lin, Linjie Li, Jianfeng Wang, Jianwei Yang, Yiwu Zhong, Julian McAuley, Jianfeng Gao, Zicheng Liu, Lijuan Wang.*<br>
arXiv 2023.11. [[PDF](http://arxiv.org/abs/2311.07562v1)]

**GPT-4V(ision) as A Social Media Analysis Engine.**<br>
*Hanjia Lyu, Jinfa Huang, Daoan Zhang, Yongsheng Yu, Xinyi Mou, Jinsheng Pan, Zhengyuan Yang, Zhongyu Wei, Jiebo Luo.*<br>
arXiv 2023.11. [[PDF](http://arxiv.org/abs/2311.07547v1)]

**On The Road with GPT-4V(ision): Early Explorations of Visual-Language Model on Autonomous Driving.**<br>
*Licheng Wen, Xuemeng Yang, Daocheng Fu, Xiaofeng Wang, Pinlong Cai, Xin Li, Tao Ma, Yingxuan Li, Linran Xu, Dengke Shang, Zheng Zhu, Shaoyan Sun, Yeqi Bai, Xinyu Cai, Min Dou, Shuanglu Hu, Botian Shi.*<br>
arXiv 2023.11. [[PDF](http://arxiv.org/abs/2311.05332v1)]

**Holistic Analysis of Hallucination in GPT-4V(ision): Bias and Interference Challenges.**<br>
*Chenhang Cui, Yiyang Zhou, Xinyu Yang, Shirley Wu, Linjun Zhang, James Zou, Huaxiu Yao.*<br>
arXiv 2023.11. [[PDF](http://arxiv.org/abs/2311.03287v2)]

**Towards Generic Anomaly Detection and Understanding: Large-scale Visual-linguistic Model (GPT-4V) Takes The Lead.**<br>
*Yunkang Cao, Xiaohao Xu, Chen Sun, Xiaonan Huang, Weiming Shen.*<br>
arXiv 2023.11. [[PDF](http://arxiv.org/abs/2311.02782v3)]

**GPT-4V(ision) as A Generalist Evaluator for Vision-Language Tasks.**<br>
*Xinlu Zhang, Yujie Lu, Weizhi Wang, An Yan, Jun Yan, Lianke Qin, Heng Wang, Xifeng Yan, William Yang Wang, Linda Ruth Petzold.*<br>
arXiv 2023.11. [[PDF](http://arxiv.org/abs/2311.01361v1)]

**A Comprehensive Study of GPT-4V's Multimodal Capabilities in Medical Imaging.**<br>
*Yingshu Li, Yunyi Liu, Zhanyu Wang, Xinyu Liang, Lingqiao Liu, Lei Wang, Leyang Cui, Zhaopeng Tu, Longyue Wang, Luping Zhou.*<br>
arXiv 2023.10. [[PDF](http://arxiv.org/abs/2310.20381v3)]

**Multimodal ChatGPT for Medical Applications: An Experimental Study of GPT-4V.**<br>
*Zhiling Yan, Kai Zhang, Rong Zhou, Lifang He, Xiang Li, Lichao Sun.*<br>
arXiv 2023.10. [[PDF](http://arxiv.org/abs/2310.19061v1)]

**Exploring OCR Capabilities of GPT-4V(ision) : A Quantitative and In-depth Evaluation.**<br>
*Yongxin Shi, Dezhi Peng, Wenhui Liao, Zening Lin, Xinhong Chen, Chongyu Liu, Yuyi Zhang, Lianwen Jin.*<br>
arXiv 2023.10. [[PDF](http://arxiv.org/abs/2310.16809v2)]

**An Early Evaluation of GPT-4V(ision).**<br>
*Yang Wu, Shilong Wang, Hao Yang, Tian Zheng, Hongbo Zhang, Yanyan Zhao, Bing Qin.*<br>
arXiv 2023.10. [[PDF](http://arxiv.org/abs/2310.16534v1)][[Github](https://github.com/albertwy/GPT-4V-Evaluation)]

**HallusionBench: You See What You Think? Or You Think What You See? An Image-Context Reasoning Benchmark Challenging for GPT-4V(ision), LLaVA-1.5, and Other Multi-modality Models.**<br>
*Fuxiao Liu, Tianrui Guan, Zongxia Li, Lichang Chen, Yaser Yacoob, Dinesh Manocha, Tianyi Zhou.*<br>
arXiv 2023.10. [[PDF](http://arxiv.org/abs/2310.14566v1)]

**Idea2Img: Iterative Self-Refinement with GPT-4V(ision) for Automatic Image Design and Generation.**<br>
*Zhengyuan Yang, Jianfeng Wang, Linjie Li, Kevin Lin, Chung-Ching Lin, Zicheng Liu, Lijuan Wang.*<br>
arXiv 2023.10. [[PDF](http://arxiv.org/abs/2310.08541v1)][[Github](https://idea2img.github.io/)]

**The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision).**<br>
*Zhengyuan Yang, Linjie Li, Kevin Lin, Jianfeng Wang, Chung-Ching Lin, Zicheng Liu, Lijuan Wang.*<br>
arXiv 2023.09. [[PDF](http://arxiv.org/abs/2309.17421v2)]
